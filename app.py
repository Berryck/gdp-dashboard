import streamlit as st
import streamlit.components.v1 as components  # æ–°å¢ï¼šç”¨äºæ˜¾ç¤ºäº¤äº’å¼ç»„ä»¶
import pickle
import joblib
import numpy as np
import shap
import pandas as pd
import matplotlib.pyplot as plt


# --- 0. è¾…åŠ©å‡½æ•°ï¼šç”¨äºåœ¨Streamlitä¸­æ˜¾ç¤ºäº¤äº’å¼SHAPå›¾ ---
def st_shap(plot, height=None):
    """
    å°† SHAP çš„ JS äº¤äº’å›¾åµŒå…¥ Streamlit
    """
    shap_html = f"<head>{shap.getjs()}</head><body>{plot.html()}</body>"
    components.html(shap_html, height=height if height else 150, scrolling=True)


# --- 1. ç¼“å­˜åŠ è½½èµ„æº ---
@st.cache_resource
def load_artifacts():
    # è½½å…¥æ¨¡å‹
    model = joblib.load("saved_models/LightGBM_Optimized.pkl")

    # è½½å…¥ Scaler
    try:
        scaler = joblib.load("saved_models/scaler1.pkl")
    except Exception:
        with open("saved_models/scaler.pkl", "rb") as f:
            scaler = pickle.load(f)

    # è½½å…¥ç‰¹å¾åç§°
    try:
        feature_names = joblib.load("saved_models/feature_names1.pkl")
    except Exception:
        with open("saved_models/feature_names.pkl", "rb") as f:
            feature_names = pickle.load(f)

    return model, scaler, feature_names


# åˆå§‹åŒ–åŠ è½½
try:
    model, scaler, feature_names = load_artifacts()
except FileNotFoundError:
    st.error("âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥ saved_models/ ç›®å½•ä¸‹æ˜¯å¦æœ‰ .pkl æ–‡ä»¶ã€‚")
    st.stop()

# --- 2. é¡µé¢é…ç½® ---
st.set_page_config(page_title="ä¸´åºŠå†³ç­–æ”¯æŒç³»ç»Ÿ", layout="wide", page_icon="ğŸ¥")
st.title("ğŸ¥ åŸºäºLightGBMçš„ä¸´åºŠé£é™©é¢„æµ‹ç³»ç»Ÿ")

# --- 3. åˆ›å»ºæ ‡ç­¾é¡µ (Tabs) ---
tab1, tab2 = st.tabs(["ğŸ“ å•ä¾‹é¢„æµ‹ (æ‰‹åŠ¨è¾“å…¥)", "ğŸ“‚ æ‰¹é‡é¢„æµ‹ (ä¸Šä¼ Excel)"])

# ==========================================
# æ¨¡å¼ä¸€ï¼šå•ä¾‹é¢„æµ‹ (æ‰‹åŠ¨è¾“å…¥)
# ==========================================
with tab1:
    st.info("é€‚ç”¨äºå¯¹å•ä¸ªæ‚£è€…è¿›è¡Œå¿«é€Ÿé£é™©è¯„ä¼°å’Œå½’å› åˆ†æã€‚")

    with st.form("single_predict_form"):
        inputs = {}
        n_cols = 4 if len(feature_names) > 10 else 2
        cols = st.columns(n_cols)

        for i, feat in enumerate(feature_names):
            with cols[i % n_cols]:
                inputs[feat] = st.number_input(f"{feat}", value=0.0, format="%.4f")

        submitted = st.form_submit_button("ğŸš€ å¼€å§‹é¢„æµ‹")

    if submitted:
        # æ•°æ®ç»„è£…
        x_df = pd.DataFrame([inputs], columns=feature_names)

        try:
            x_scaled = scaler.transform(x_df)

            # é¢„æµ‹
            if hasattr(model, "predict_proba"):
                prob = model.predict_proba(x_scaled)[0, 1]
            else:
                prob = model.predict(x_scaled)[0]

            # æ˜¾ç¤ºç»“æœ
            st.divider()
            c1, c2 = st.columns([1, 2])
            with c1:
                st.subheader("é¢„æµ‹ç»“æœ")
                st.metric("é£é™©æ¦‚ç‡", f"{prob * 100:.2f}%")
                if prob > 0.5:
                    st.error("ğŸ”´ é«˜é£é™© (High Risk)")
                else:
                    st.success("ğŸŸ¢ ä½é£é™© (Low Risk)")

            # SHAP è§£é‡Š
            with c2:
                st.subheader("ä¸ªä½“å½’å› åˆ†æ")
                with st.spinner("æ­£åœ¨è®¡ç®—ç‰¹å¾è´¡çŒ®åº¦..."):
                    explainer = shap.TreeExplainer(model)
                    shap_values_all = explainer.shap_values(x_scaled)

                    if isinstance(shap_values_all, list):
                        shap_values = shap_values_all[1]
                        base_value = explainer.expected_value[1]
                    else:
                        shap_values = shap_values_all
                        base_value = explainer.expected_value
                        if isinstance(base_value, np.ndarray): base_value = base_value[0]

                    # 1. ç€‘å¸ƒå›¾ (Waterfall Plot)
                    st.markdown("**1. ç€‘å¸ƒå›¾ (Waterfall Plot)** - å±•ç¤ºç´¯ç§¯è´¡çŒ®")
                    explanation = shap.Explanation(
                        values=shap_values[0],
                        base_values=base_value,
                        data=x_df.iloc[0],
                        feature_names=feature_names
                    )
                    fig = plt.figure(figsize=(10, 5))
                    shap.plots.waterfall(explanation, max_display=10, show=False)
                    st.pyplot(fig, bbox_inches='tight')
                    plt.close(fig)

                    # 2. åŠ›å›¾ (Force Plot) - æ–°å¢åŠŸèƒ½
                    st.markdown("**2. åŠ›å›¾ (Force Plot)** - äº¤äº’å¼æ‹”æ²³å›¾")
                    st.caption("é¼ æ ‡æ‚¬åœåœ¨å›¾è¡¨ä¸Šå¯æŸ¥çœ‹å…·ä½“æ•°å€¼ã€‚")
                    # æ³¨æ„ï¼šforce_plot éœ€è¦ matplotlib=False æ‰èƒ½ç”Ÿæˆ JS äº¤äº’å›¾
                    force_plot_html = shap.force_plot(
                        base_value,
                        shap_values[0],
                        x_df.iloc[0],
                        feature_names=feature_names,
                        matplotlib=False
                    )
                    st_shap(force_plot_html, height=160)

        except Exception as e:
            st.error(f"è¿è¡Œå‡ºé”™: {e}")
            import traceback

            st.text(traceback.format_exc())

# ==========================================
# æ¨¡å¼äºŒï¼šæ‰¹é‡é¢„æµ‹ (ä¸Šä¼ Excel)
# ==========================================
with tab2:
    st.info("é€‚ç”¨äºå¤„ç†å¤šæ¡æ•°æ®ã€‚è¯·ä¸Šä¼  Excel (.xlsx) æˆ– CSV æ–‡ä»¶ã€‚")

    # 1. ä¸‹è½½æ¨¡æ¿
    with st.expander("ğŸ“¥ ä¸‹è½½æ•°æ®æ¨¡æ¿"):
        st.write("è¯·ç¡®ä¿æ‚¨çš„è¡¨æ ¼åŒ…å«ä»¥ä¸‹åˆ—åï¼š")
        st.code(str(feature_names), language="python")
        template_df = pd.DataFrame(columns=['Patient_ID'] + feature_names)
        csv = template_df.to_csv(index=False).encode('utf-8')
        st.download_button("ä¸‹è½½ CSV æ¨¡æ¿", csv, "prediction_template.csv", "text/csv")

    # 2. æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader("ä¸Šä¼ æ–‡ä»¶", type=["xlsx", "csv"])

    if uploaded_file:
        try:
            if uploaded_file.name.endswith('.csv'):
                try:
                    df_upload = pd.read_csv(uploaded_file)
                except UnicodeDecodeError:
                    uploaded_file.seek(0)
                    df_upload = pd.read_csv(uploaded_file, encoding='gbk')
            else:
                df_upload = pd.read_excel(uploaded_file)

            st.write(f"âœ… æˆåŠŸè¯»å– {len(df_upload)} æ¡æ•°æ®ã€‚")

            df_upload.columns = df_upload.columns.str.strip()
            missing_cols = [col for col in feature_names if col not in df_upload.columns]

            if missing_cols:
                st.error(f"âŒ æ–‡ä»¶ç¼ºå°‘ä»¥ä¸‹å¿…è¦ç‰¹å¾åˆ—ï¼š\n{missing_cols}")
            else:
                X_batch = df_upload[feature_names]
                X_batch_scaled = scaler.transform(X_batch)

                if hasattr(model, "predict_proba"):
                    probs = model.predict_proba(X_batch_scaled)[:, 1]
                else:
                    probs = model.predict(X_batch_scaled)

                df_result = df_upload.copy()
                df_result['é¢„æµ‹æ¦‚ç‡'] = np.round(probs, 4)
                df_result['é£é™©ç­‰çº§'] = ['é«˜é£é™©' if p > 0.5 else 'ä½é£é™©' for p in probs]

                st.subheader("ğŸ“Š é¢„æµ‹ç»“æœæ¦‚è§ˆ")
                st.dataframe(df_result.style.applymap(
                    lambda x: 'background-color: #ffcccc' if x == 'é«˜é£é™©' else 'background-color: #ccffcc',
                    subset=['é£é™©ç­‰çº§']
                ))

                csv_result = df_result.to_csv(index=False).encode('utf-8-sig')
                st.download_button("ğŸ’¾ ä¸‹è½½é¢„æµ‹ç»“æœ (.csv)", csv_result, "prediction_results.csv", "text/csv")

                # 7. æ·±å…¥åˆ†æ
                st.divider()
                st.subheader("ğŸ” æ·±å…¥åˆ†æï¼šæŸ¥çœ‹ç‰¹å®šæ‚£è€…çš„SHAPè§£é‡Š")
                selected_index = st.selectbox(
                    "é€‰æ‹©è¦åˆ†æçš„è¡Œå· (Index)",
                    options=df_result.index,
                    format_func=lambda x: f"è¡Œ {x} (æ¦‚ç‡: {df_result.loc[x, 'é¢„æµ‹æ¦‚ç‡']:.2%})"
                )

                if st.button("è§£é‡Šè¯¥æ‚£è€…"):
                    x_single_df = X_batch.iloc[[selected_index]]
                    x_single_scaled = X_batch_scaled[selected_index].reshape(1, -1)

                    explainer = shap.TreeExplainer(model)
                    shap_values_all = explainer.shap_values(x_single_scaled)

                    if isinstance(shap_values_all, list):
                        sv = shap_values_all[1][0]
                        bv = explainer.expected_value[1]
                    else:
                        sv = shap_values_all[0]
                        bv = explainer.expected_value
                        if isinstance(bv, np.ndarray): bv = bv[0]

                    # 1. ç€‘å¸ƒå›¾
                    st.markdown("**1. ç€‘å¸ƒå›¾ (Waterfall Plot)**")
                    exp = shap.Explanation(
                        values=sv, base_values=bv,
                        data=x_single_df.iloc[0], feature_names=feature_names
                    )
                    fig_batch = plt.figure(figsize=(10, 5))
                    shap.plots.waterfall(exp, max_display=10, show=False)
                    st.pyplot(fig_batch, bbox_inches='tight')
                    plt.close(fig_batch)

                    # 2. åŠ›å›¾ (æ–°å¢)
                    st.markdown("**2. åŠ›å›¾ (Force Plot)**")
                    force_plot_html_batch = shap.force_plot(
                        bv,
                        sv,
                        x_single_df.iloc[0],
                        feature_names=feature_names,
                        matplotlib=False
                    )
                    st_shap(force_plot_html_batch, height=160)

        except Exception as e:
            st.error(f"å¤„ç†æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
